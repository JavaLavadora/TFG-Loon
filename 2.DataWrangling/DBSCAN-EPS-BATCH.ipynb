{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "import sklearn.utils\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import math\n",
    "from math import radians\n",
    "import datetime\n",
    "\n",
    "from keplergl import KeplerGl\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.1         1.14736842  2.19473684  3.24210526  4.28947368  5.33684211\n",
      "  6.38421053  7.43157895  8.47894737  9.52631579 10.57368421 11.62105263\n",
      " 12.66842105 13.71578947 14.76315789 15.81052632 16.85789474 17.90526316\n",
      " 18.95263158 20.        ]\n",
      "N225LB: [  -1    0    1 ... 1289 1290 1291]; eps=1.5696101377226163e-05; max_distance= 0.1\n",
      "N225LB: [-1  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22\n",
      " 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46\n",
      " 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68]; eps=0.0001800921105387002; max_distance= 1.1473684210526316\n",
      "N225LB: [-1  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22\n",
      " 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40]; eps=0.0003444881197001742; max_distance= 2.194736842105263\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-27f0f5cab1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# For now we set MinPoints = 4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDBSCAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ball_tree'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'haversine'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                 \u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mradians\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdbscan_bl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         print(str(loon) + ': ' + str(np.unique(db.labels_)) + '; eps=' + str(eps) \\\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/cluster/_dbscan.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    348\u001b[0m         core_samples = np.asarray(n_neighbors >= self.min_samples,\n\u001b[1;32m    349\u001b[0m                                   dtype=np.uint8)\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mdbscan_inner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighborhoods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore_sample_indices_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ['N252LB', 'N253LB', 'N271LB', 'N329LB', 'N789LB', 'N235LB']\n",
    "\n",
    "# Loons to compute\n",
    "target_loons = ['N225LB', 'N253LB']\n",
    "\n",
    "\n",
    "#-------------------USER INPUT!!!-------------------\n",
    "\n",
    "# Compute the range of distances to be used in DBSCAN\n",
    "num_values = 20\n",
    "start_distance = 0.1\n",
    "end_distance = 20\n",
    "\n",
    "step_size = (end_distance - start_distance) / (num_values-1)\n",
    "max_distances = np.arange(start_distance, end_distance + step_size, step_size)\n",
    "\n",
    "print(max_distances)\n",
    "\n",
    "#---------------------------------------------------\n",
    "\n",
    "\n",
    "# Iterate over the batch\n",
    "\n",
    "for loon in target_loons:\n",
    "\n",
    "    # First the loon data is read\n",
    "    bl = pd.read_csv('../../../../og_data/' + loon + '.csv', parse_dates=['ts'], low_memory=False) \n",
    "    \n",
    "    kms_per_radian = 6371.0088\n",
    "\n",
    "    # Compute the DBSCANs with the range of distances\n",
    "    for distance in max_distances:\n",
    "\n",
    "        dbscan_bl = StandardScaler().fit_transform(bl[['lat', 'lon']])\n",
    "\n",
    "        # eps parameter must be in radians\n",
    "        eps = distance / kms_per_radian\n",
    "\n",
    "        # For now we set MinPoints = 4\n",
    "        db = DBSCAN(eps=eps, min_samples=4, algorithm='ball_tree', metric='haversine') \\\n",
    "                .fit(np.radians(dbscan_bl))\n",
    "\n",
    "        print(str(loon) + ': ' + str(np.unique(db.labels_)) + '; eps=' + str(eps) \\\n",
    "                + '; max_distance= ' + str(distance))\n",
    "\n",
    "        bl['cluster'] = db.labels_\n",
    "        bl['eps'] = eps\n",
    "        bl['max_distance'] = distance\n",
    "\n",
    "\n",
    "        # Save clustered baseline to file   \n",
    "        bl.to_csv( '../../../../og_data/DBSCAN/epsRange/' + str(loon) \\\n",
    "                                      + '/CL-' + loon \\\n",
    "                                      + '-' + 'mp_4' + '-eps_' + str(eps) \\\n",
    "                                      + '.csv', index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
