{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "import sklearn.utils\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keplergl import KeplerGl\n",
    "import geopandas as gpd\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "from st_dbscan import ST_DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We switched to fr data\n",
    "# bl = pd.read_csv('../../../../og_data/extract_clean_with_country.csv', index_col='Unnamed: 0', parse_dates=['ts'], low_memory=False)\n",
    "\n",
    "fr = pd.DataFrame()\n",
    "\n",
    "flights_to_add = ['HBAL102-N235LB', 'HBAL116-N252LB', 'HBAL131-N271LB', 'HBAL132-N211LB', \\\n",
    "                  'HBAL136-N238LB']\n",
    "\n",
    "for flight in flights_to_add:\n",
    "    \n",
    "    aux = pd.read_csv('../../../../og_data/' + flight + '.csv', parse_dates=['ts'], low_memory=False)\n",
    "    \n",
    "    fr = fr.append(aux)\n",
    "\n",
    "fr['trip_id'] = fr['aircraft_id']\n",
    "\n",
    "bl = fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Guide: https://github.com/keplergl/kepler.gl/blob/master/docs/keplergl-jupyter/user-guide.md\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8d299fde37542d1a99786636d81d4fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "KeplerGl(height=700)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize with Kepler\n",
    "#Create a basemap \n",
    "map = KeplerGl(height=700, width=800)#show the map\n",
    "map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Third attempt with only DBSCAN + filters'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'First attempt with only DBSCAN'\n",
    "'Third attempt with only DBSCAN + filters'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median is: 0 days 00:01:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: FutureWarning: Passing integers to fillna is deprecated, will raise a TypeError in a future version.  To retain the old behavior, pass pd.Timedelta(seconds=n) instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# First let's study the frequency of records\n",
    "freq_df = pd.DataFrame()\n",
    "\n",
    "freq_df = bl.loc[bl.registration_id == 'N238LB'].copy()\n",
    "freq_df = freq_df.sort_values('ts')\n",
    "\n",
    "freq_df['time_since_last_record'] = freq_df['ts'] - freq_df['ts'].shift()\n",
    "freq_df['time_since_last_record'] = freq_df['time_since_last_record'].fillna(0)\n",
    "\n",
    "# Go for the median since it is less sensitive to outliers\n",
    "freq_median = freq_df['time_since_last_record'].median()\n",
    "print('Median is: ' + str(freq_median))\n",
    "\n",
    "\n",
    "stay_duration = pd.Timedelta('1day')\n",
    "\n",
    "# Min number of samples there should be for the duration of what we consider a stay\n",
    "min_stay_records = stay_duration / freq_median\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1416.3934426229507"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_stay_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N238LB: [-1  0  1  2  3  4  5  6  7  8  9 10 11]\n"
     ]
    }
   ],
   "source": [
    "#sample_trip = pd.DataFrame()\n",
    "#sample_trip = bl.loc[bl.trip_id == 'HBAL027-BA1462'].copy()\n",
    "\n",
    "\n",
    "trips_to_study = ['N238LB']\n",
    "#['N235LB', 'N252LB', 'N271LB', 'N211LB', 'N238LB']\n",
    "\n",
    "'''['HBAL438-BA10EF', 'HBAL11-BA116D', 'HBAL14-BA116F', \\\n",
    "                     'HBAL17-BA1182', 'HBAL464-BA115A', 'HBAL465-BA115B', \\\n",
    "                     'HBAL390-BA1114', 'HBAL19-BA1190', 'HBAL0329-A27A9E', \\\n",
    "                     'HBAL470-BA118E', 'HBAL448-BA1162']\n",
    "                     \n",
    "                     \n",
    "                     \n",
    " ['HBAL026-BA144D','HBAL027-BA1462','HBAL029-BA1440','HBAL034-BA1475', \\\n",
    "                            'HBAL036-BA147A','HBAL045-BA14B7','HBAL046-A20D33','HBAL047-A22EA2', \\\n",
    "                            'HBAL049-A22734','HBAL076-A1D836','HBAL085-A0D299','HBAL086-A19E24', \\\n",
    "                            'HBAL095-A2B654','HBAL097-A16317','HBAL187-A2E18A','HBAL187-BA13C2', \\\n",
    "                            'HBAL209-BA1493','HBAL218-BA13EB','HBAL231-BA1460' ]\n",
    "'''\n",
    "\n",
    "trips_with_cluster = pd.DataFrame()\n",
    "\n",
    "for trip in trips_to_study:\n",
    "    \n",
    "    trip_df_temp = bl.loc[bl.registration_id == trip].copy()\n",
    "    \n",
    "    trip_df_temp_clus = StandardScaler().fit_transform(trip_df_temp[['lat', 'lon']])\n",
    "    db = DBSCAN(eps=0.05, min_samples=1500, metric='euclidean').fit(trip_df_temp_clus)\n",
    "\n",
    "    trip_df_temp['cluster'] = db.labels_\n",
    "    print(str(trip) + ': ' + str(np.unique(db.labels_)))\n",
    "    \n",
    "    trips_with_cluster = trips_with_cluster.append(trip_df_temp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame(trips_with_cluster, \\\n",
    "                       geometry=gpd.points_from_xy(trips_with_cluster.lon, trips_with_cluster.lat))\n",
    "\n",
    "map.add_data(data=gdf, name=\"loon_traces\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file\n",
    "trips_with_cluster.to_csv('trips_with_cluster.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Second attempt with spatiotemporal DBSCAN' DESCARTADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N271LB\n"
     ]
    }
   ],
   "source": [
    "DESCARTADO\n",
    "\n",
    "\n",
    "trips_to_study = ['N271LB']\n",
    "\n",
    "\n",
    "'''\n",
    "['HBAL026-BA144D','HBAL027-BA1462','HBAL029-BA1440','HBAL034-BA1475', \\\n",
    "                            'HBAL036-BA147A','HBAL045-BA14B7','HBAL046-A20D33','HBAL047-A22EA2', \\\n",
    "                            'HBAL049-A22734','HBAL076-A1D836','HBAL085-A0D299','HBAL086-A19E24', \\\n",
    "                            'HBAL095-A2B654','HBAL097-A16317','HBAL187-A2E18A','HBAL187-BA13C2', \\\n",
    "                            'HBAL209-BA1493','HBAL218-BA13EB','HBAL231-BA1460' ]\n",
    "\n",
    "['HBAL072', 'HBAL102', 'HBAL131', 'HBAL132', \\\n",
    "                  'HBAL136', 'HBAL116']\n",
    "'''\n",
    "\n",
    "\n",
    "    \n",
    "trips_with_cluster = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "for trip in trips_to_study:\n",
    "    print(str(trip))\n",
    "    trip_df = bl.loc[(bl.registration_id == trip)].copy()\n",
    "\n",
    "    # Normalize the data\n",
    "    trip_df['lat_normal'] = (trip_df['lat'] - trip_df['lat'].min()) / (trip_df['lat'].max() - trip_df['lat'].min())\n",
    "    trip_df['lon_normal'] = (trip_df['lon'] - trip_df['lon'].min()) / (trip_df['lon'].max() - trip_df['lon'].min())\n",
    "    trip_df['ts_delta'] = (trip_df['ts'] - trip_df['ts'].min())  / np.timedelta64(1,'D')\n",
    "\n",
    "    # transform to numpy array\n",
    "    data = trip_df.loc[:, ['ts_delta','lat_normal','lon_normal']].values\n",
    "\n",
    "    # fit\n",
    "    st_dbscan = ST_DBSCAN(eps1 = 0.03, eps2 = 5, min_samples = 1400) \n",
    "    st_dbscan.fit(data)\n",
    "    #st_dbscan.fit_frame_split(data, frame_size = 50)\n",
    "\n",
    "    # Add cluster data to the df\n",
    "    trip_df['cluster'] = st_dbscan.labels\n",
    "    print(str(trip) + ': ' + str(np.unique(st_dbscan.labels)))\n",
    "\n",
    "    trips_with_cluster = trips_with_cluster.append(trip_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame(trips_with_cluster, \\\n",
    "                       geometry=gpd.points_from_xy(trips_with_cluster.lon, trips_with_cluster.lat))\n",
    "\n",
    "map.add_data(data=gdf, name=\"loon_traces\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
